---
datePublished: 2024-07-04
draft: true
inlineCodeLanguage: rust
---

# Optimizing rounded f32-to-int conversion

I recently came across a problem where I needed to convert a 5-bit unorm to a 8-bit unorm. "Unorm" means **u**nsigned **norm**alized, and unorm numbers are n-bit unsigned integer that represent a (floating-point) number between 0 and 1.

One of the most common application are unorms are colors in computer graphics:

-   most image editing programs use 8-bit unorms to represent RGB color channels,
-   the web uses hex-encoded 8-bit unorms (e.g. `#FF0000` for red) and 4-bit unorms (e.g. `#F00` is also red) for colors, and
-   some games store textures as `B5G5R5A1_UNORM`, which uses 5-bit unorms for the RGB channels and a 1-bit unorm for the alpha channel, to store an RGBA color in just 2 bytes.

The value of an n-bit unorm $x$ is calculated as:

$$
\frac{x}{2^n - 1}
$$

The formula for converting an n-bit unorm to an 8-bit unorm is similarly simple:

$$
round(\frac{x}{2^n - 1} \cdot 255)
$$

Rounding is necessary to get the 8-bit unorm closest to the original n-bit value.

Simple enough, here's a naive Rust implementation of this formula for converting a 5-bit integer:

```rust
fn u5_to_u8_naive(x: u8) -> u8 {
    debug_assert!(x < 32);
    (x as f32 / 31.0 * 255.0).round() as u8
}
```

<div class="info">

<details>
<summary>
For those unfamiliar with Rust:
</summary>

-   `u8` is an **8**-bit **u**nsigned integer.
-   `f32` is a **32**-bit **f**loating point number.
-   `expr as T` is a cast between primitive types (`(T) expr` in C).
-   `fn` is the keyword for [defining a function](https://doc.rust-lang.org/book/ch03-03-how-functions-work.html) and `-> T` annotates the return type.
-   The last expression in a function body is the return value of the function.
-   `debug_assert!` checks a condition at runtime and crashes the program if it's false. The check is only included in debug/test build.
-   `expr.round()` rounds a floating point number the nearest integer. \
    In Rust, `round` and other floating point operations are instance methods on the `f32` type.

I will explain more Rust-specific concepts as them come up. Otherwise, Rust generally has a C-like syntax and semantics, so if something looks like C, it will most likely behave like it too.

</details>

</div>

This works correctly and gets the job done. There's only one problem: it's slow.

To decode a single 1024x1024 `B5G5R5A1_UNORM` texture, this function needs to be called **3.1 Million** times. So it better be fast.

## Contents

## Benchmarking

Before we start optimizing, let's define a benchmark.

Since there are only 32 possible input value for our 5 bit to 8 bit conversion, we'll just fill a list with 1024 random values between 0 and 31 and convert all of them. Since we're calling the conversion function in a tight loop, we're benchmarking not only the function itself, but also how well the compiler can vectorize it.

This setup is actually quite close to what an actual image decoder would do. The only difference is that the real-world use-case likely won't vectorize quite as well, so the benchmarks will be a bit optimistic.

All benchmarks in this article were performed with [`criterion`](https://bheisler.github.io/criterion.rs/book/criterion_rs.html) and with the following environment:

-   OS: Windows 10
-   CPU: Intel(R) Core(TM) i7-8700K CPU @ 3.70GHz
-   Rust: 1.78.0

Here is the result for the naive implementation:

```
                    low       expected       high
u5_to_u8_naive     [11.108 µs 11.147 µs 11.195 µs]
```

<div class="info">

`criterion` reports a [confidence interval](https://bheisler.github.io/criterion.rs/book/user_guide/command_line_output.html#time). The left and right values are the lower and upper bounds of the interval, respectively. `criterion` is 95% confident that the real per-iteration runtime is inside this interval. The center value is `criterion`'s best estimate of the actual runtime per iteration.

**Use the center value** for a simple way to compare the performance of different implementations.

</div>

Scaling this up to 3.1 million calls, we get an optimistically estimated runtime of 34 ms to decode a single 1024x1024 texture. Considering that modern AAA games need to load around 1000 textures, that's not great. Nobody wants to wait half a minute for a game to load.

TODO: Source code for the benchmarks

## Simple optimizations

Let's start by taking a look at the assembly generated by the naive implementation. I'm using [compiler explorer](<https://godbolt.org/#g:!((g:!((g:!((h:codeEditor,i:(filename:'1',fontScale:14,fontUsePx:'0',j:1,lang:rust,selection:(endColumn:12,endLineNumber:7,positionColumn:12,positionLineNumber:7,selectionStartColumn:12,selectionStartLineNumber:7,startColumn:12,startLineNumber:7),source:'%23%5Bno_mangle%5D%0Apub+fn+u5_to_u8_naive(x:+u8)+-%3E+u8+%7B%0A++++debug_assert!!(x+%3C+32)%3B%0A++++(x+as+f32+/+31.0+*+255.0).round()+as+u8%0A%7D%0A%0Afn+main()+%7B%7D%0A'),l:'5',n:'1',o:'Rust+source+%231',t:'0')),k:46.58379142816912,l:'4',n:'0',o:'',s:0,t:'0'),(g:!((g:!((h:compiler,i:(compiler:r1780,filters:(b:'0',binary:'1',binaryObject:'1',commentOnly:'1',debugCalls:'1',demangle:'0',directives:'0',execute:'1',intel:'0',libraryCode:'0',trim:'1',verboseDemangling:'0'),flagsViewOpen:'1',fontScale:14,fontUsePx:'0',j:1,lang:rust,libs:!(),options:'-C+opt-level%3D2',overrides:!((name:edition,value:'2021')),selection:(endColumn:1,endLineNumber:1,positionColumn:1,positionLineNumber:1,selectionStartColumn:1,selectionStartLineNumber:1,startColumn:1,startLineNumber:1),source:1),l:'5',n:'0',o:'+rustc+1.78.0+(Editor+%231)',t:'0')),k:53.41620857183087,l:'4',m:50,n:'0',o:'',s:0,t:'0'),(g:!((h:executor,i:(argsPanelShown:'1',compilationPanelShown:'0',compiler:r1780,compilerName:'',compilerOutShown:'0',execArgs:'',execStdin:'',fontScale:14,fontUsePx:'0',j:1,lang:rust,libs:!(),options:'',overrides:!((name:edition,value:'2021')),runtimeTools:!(),source:1,stdinPanelShown:'1',wrap:'1'),l:'5',n:'0',o:'Executor+rustc+1.78.0+(Rust,+Editor+%231)',t:'0')),header:(),l:'4',m:50,n:'0',o:'',s:0,t:'0')),k:53.41620857183087,l:'3',n:'0',o:'',t:'0')),l:'2',n:'0',o:'',t:'0')),version:4>) for this.

I added comments for all relevant instructions, so knowing assembly is not required to follow along.

```rust
fn u5_to_u8_naive(x: u8) -> u8 {
    debug_assert!(x < 32);
    (x as f32 / 31.0 * 255.0).round() as u8
}
```

```asm
.LCPI0_0:
        .long   0x41f80000 ; 31.0 (f32)
.LCPI0_1:
        .long   0x437f0000 ; 255.0 (f32)
u5_to_u8_naive:
        push    rax
        movzx   eax, dil
        cvtsi2ss        xmm0, eax                 ; xmm0 = x to f32
        divss   xmm0, dword ptr [rip + .LCPI0_0]  ; xmm0 = xmm0 / 31.0
        mulss   xmm0, dword ptr [rip + .LCPI0_1]  ; xmm0 = xmm0 * 255.0
        call    qword ptr [rip + roundf@GOTPCREL] ; xmm0 = round(xmm0)
        xorps   xmm1, xmm1                        ; xmm1 = 0.0             \
        maxss   xmm1, xmm0                        ; xmm1 = max(xmm1, xmm0)  \
        movss   xmm0, dword ptr [rip + .LCPI0_1]  ; xmm0 = 255.0             | as u8
        minss   xmm0, xmm1                        ; xmm0 = min(xmm0, xmm1)  /
        cvttss2si       eax, xmm0                 ; convert xmm0 to int    /
        pop     rcx
        ret
```

Despite compiling in release mode with optimization enabled, the assembly is a fairly literal translation of our code (aside from the `debug_assert!`). One thing that sticks out are the `min`/`max` operations. Rust clamps floating-point values to the range 0-255 before converting them to an integer to avoid undefined behavior. Safety first.

Well, we can't expect the compiler to do all the work, so let's see what we can optimize.

One trivial optimization is to avoid the division. `/ 31.0 * 255.0` can be replaced with a multiplication by a constant to save a floating-point division. Instead of defining the constant as a variable or `const`ant, I'll use a little trick and write `* (255.0 / 31.0)`. This allows the compiler to compute the constant at compile time with only minimal changes to the code.

Another optimization is that we can remove the call to `round`. Rust guarantees that [`as u8` truncates](https://doc.rust-lang.org/reference/expressions/operator-expr.html#numeric-cast) the floating-point number, so we can use this identity:

$$
round(x) = trunc(x + 0.5), \space \forall x\ge 0
$$

Putting both optimizations into code:

```rust
fn u5_to_u8_v2(x: u8) -> u8 {
    debug_assert!(x < 32);
    (x as f32 * (255.0 / 31.0) + 0.5) as u8
}
```

```asm
.LCPI0_0:
        .long   0x41039ce7 ; 8.22580624 (f32)
.LCPI0_1:
        .long   0x3f000000 ; 0.5 (f32)
.LCPI0_2:
        .long   0x437f0000 ; 255.0 (f32)
u5_to_u8_v2:
        movzx   eax, dil
        cvtsi2ss        xmm0, eax                ; xmm0 = x to f32
        mulss   xmm0, dword ptr [rip + .LCPI0_0] ; xmm0 = xmm0 * 8.22580624 (= 255/31)
        addss   xmm0, dword ptr [rip + .LCPI0_1] ; xmm0 = xmm0 + 0.5
        xorps   xmm1, xmm1                       ; xmm1 = 0.0              \
        maxss   xmm1, xmm0                       ; xmm1 = max(xmm1, xmm0)   \
        movss   xmm0, dword ptr [rip + .LCPI0_2] ; xmm0 = 255.0              | as u8
        minss   xmm0, xmm1                       ; xmm0 = min(xmm0, xmm1)   /
        cvttss2si       eax, xmm0                ; convert xmm0 to int     /
        ret
```

That assembly looks much better. No division and no call to `round`. Let's see how fast it is:

```
                    low       expected       high
u5_to_u8_naive     [11.108 µs 11.147 µs 11.195 µs]
u5_to_u8_v2        [1.3806 µs 1.3848 µs 1.3898 µs]
```

That's a generous 8x speedup.

The improvement comes mostly from avoiding the call to `round`. While floating-point division is slow compared to other arithmetic, non-inlined function calls are quite expensive as well.

<div class="side-note">

Rounding (compared to floating-point arithmetic) is quite an expensive operation, because rounding is surprisingly non-trivial. The full definition for $round(x)$ is inherently brachy:

$$
round(x) = \begin{cases}
    \lfloor x + 0.5 \rfloor & \text{if } x \ge 0 \\
    \lceil x - 0.5 \rceil & \text{otherwise}
\end{cases}
$$

Implementing this formula might _seems_ straightforward, but floating-point numbers only have a finite precision, so adding/subtracting 0.5 will return a _rounded_ result. All assertions in the following code will pass:

```rust runnable
fn simple_round(x: f32) -> f32 {
    if x >= 0.0 {
        (x + 0.5).floor()
    } else {
        (x - 0.5).ceil()
    }
}

let a: f32 = 0.49999997;
assert!(a < 0.5);
assert!(a + 0.5 == 1.0);
assert!((a + 0.5).floor() == 1.0);
assert!(simple_round(a) == 1.0);
assert!(a.round() == 0.0);
println!("All asserts passed!");
```

So always be careful when implementing mathematical formulas when floating-point numbers are involved.

</div>

## Faster with `unsafe`

Let's look at the assembly of the previous function again:

```asm
.LCPI0_0:
        .long   0x41039ce7 ; 8.22580624 (f32)
.LCPI0_1:
        .long   0x3f000000 ; 0.5 (f32)
.LCPI0_2:
        .long   0x437f0000 ; 255.0 (f32)
u5_to_u8_v2:
        movzx   eax, dil
        cvtsi2ss        xmm0, eax                ; xmm0 = x to f32
        mulss   xmm0, dword ptr [rip + .LCPI0_0] ; xmm0 = xmm0 * 8.22580624 (= 255/31)
        addss   xmm0, dword ptr [rip + .LCPI0_1] ; xmm0 = xmm0 + 0.5
        xorps   xmm1, xmm1                       ; xmm1 = 0.0              \
        maxss   xmm1, xmm0                       ; xmm1 = max(xmm1, xmm0)   \
        movss   xmm0, dword ptr [rip + .LCPI0_2] ; xmm0 = 255.0              | as u8
        minss   xmm0, xmm1                       ; xmm0 = min(xmm0, xmm1)   /
        cvttss2si       eax, xmm0                ; convert xmm0 to int     /
        ret
```

As we can see, Rust clamps to the range 0-255 before converting the floating-point number to an integer. This is necessary to guarantee safety in the general case. So e.g. `300_f32 as u8` will return `255_u8`. This is unlike C/C++, where no clamping is performed and converting floating-point values that cannot be represented by the target integer type is undefined behavior. So e.g. `(uint8_t) 300.0f` in C is UB.

However, the clamping is entirely unnecessary in our case. Since we know that the input value `x` for the 5 bit to 8 bit conversion is between 0 and 31, we know that the floating-point value being converted will always be between 0.5 and 255.5. Since `as u8` truncates, the floating-point value will always be in-range for `u8`.

Luckily, Rust has a way out. We can use [`f32::to_int_unchecked`](https://doc.rust-lang.org/std/primitive.f32.html#method.to_int_unchecked) to perform the integer conversion without clamping. This function also comes with the same undefined behavior as C, so we need to use `unsafe`.

```rust
/// ## Safety
/// The caller must ensure `x < 32`.
unsafe fn u5_to_u8_unsafe(x: u8) -> u8 {
    debug_assert!(x < 32);
    let f = x as f32 * (255.0 / 31.0) + 0.5;
    unsafe { f.to_int_unchecked() }
}
```

```asm
.LCPI0_0:
        .long   0x41039ce7
.LCPI0_1:
        .long   0x3f000000
u5_to_u8_unsafe:
        movzx   eax, dil
        cvtsi2ss        xmm0, eax                ; xmm0 = x to f32
        mulss   xmm0, dword ptr [rip + .LCPI0_0] ; xmm0 = xmm0 * 8.22580624 (255 / 31)
        addss   xmm0, dword ptr [rip + .LCPI0_1] ; xmm0 = xmm0 + 0.5
        cvttss2si       eax, xmm0                ; convert xmm0 to u8
        ret
```

```
                    low       expected       high
u5_to_u8_naive     [11.108 µs 11.147 µs 11.195 µs]
u5_to_u8_v2        [1.3806 µs 1.3848 µs 1.3898 µs]
u5_to_u8_unsafe    [614.04 ns 615.98 ns 618.32 ns]
```

That's 2.25x faster than the previous version, and 18x faster than the naive implementation.

Unfortunately, the function is `unsafe` will cause undefined behavior if used incorrectly. This makes the function harder to use, as a small mistake can lead to a crash _in the best case_.

## Complaining about LLVM code gen

I want to briefly return to the assembly LLVM generated for the previous safe version:

```rust
fn u5_to_u8_v2(x: u8) -> u8 {
    debug_assert!(x < 32);
    (x as f32 * (255.0 / 31.0) + 0.5) as u8
}
```

```asm
.LCPI0_0:
        .long   0x41039ce7 ; 8.22580624 (f32)
.LCPI0_1:
        .long   0x3f000000 ; 0.5 (f32)
.LCPI0_2:
        .long   0x437f0000 ; 255.0 (f32)
u5_to_u8_v2:
        movzx   eax, dil
        cvtsi2ss        xmm0, eax                ; xmm0 = x to f32
        mulss   xmm0, dword ptr [rip + .LCPI0_0] ; xmm0 = xmm0 * 8.22580624 (= 255/31)
        addss   xmm0, dword ptr [rip + .LCPI0_1] ; xmm0 = xmm0 + 0.5
        xorps   xmm1, xmm1                       ; xmm1 = 0.0              \
        maxss   xmm1, xmm0                       ; xmm1 = max(xmm1, xmm0)   \
        movss   xmm0, dword ptr [rip + .LCPI0_2] ; xmm0 = 255.0              | as u8
        minss   xmm0, xmm1                       ; xmm0 = min(xmm0, xmm1)   /
        cvttss2si       eax, xmm0                ; convert xmm0 to int     /
        ret
```

This assembly is suboptimal. The `movss` could have easily been avoided with a slightly smarter use of registers. This is the type of low-level micro-optimization that compilers should excel at, so I don't understand why LLVM missed it here.

```asm
u5_to_u8e_v2:
        movzx   eax, dil
        cvtsi2ss        xmm1, eax                ; xmm0 = x to f32
        mulss   xmm0, dword ptr [rip + .LCPI0_0] ; xmm0 = xmm0 * 8.22580624 (= 255/31)
        addss   xmm0, dword ptr [rip + .LCPI0_1] ; xmm0 = xmm0 + 0.5
        xorps   xmm1, xmm1                       ; xmm1 = 0.0              \
        maxss   xmm0, xmm1                       ; xmm0 = max(xmm0, xmm1)   |
        minss   xmm0, dword ptr [rip + .LCPI0_2] ; xmm0 = min(xmm0, 255.0)  | as u8
        cvttss2si       eax, xmm0                ; convert xmm0 to int     /
        ret
```

But that's not all. A sufficiently smart compiler could have optimized away the `maxss` and `xorps` as well.

The compiler knows that `x: u16` implies that `x >= 0`. So it could have known that `x as f32 * (255.0 / 31.0) + 0.5` is always `>= 0.5`, and thus the `max(0, num)` part of the clamping is unnecessary. Removing the `max(0, z)` part would have allowed the compiler to remove the `xorps` and `maxss` instructions like so:

```asm
u5_to_u8_v2:
        movzx   eax, dil
        cvtsi2ss        xmm1, eax                ; xmm0 = x to f32
        mulss   xmm0, dword ptr [rip + .LCPI0_0] ; xmm0 = xmm0 * 8.22580624 (= 255/31)
        addss   xmm0, dword ptr [rip + .LCPI0_1] ; xmm0 = xmm0 + 0.5
        minss   xmm0, dword ptr [rip + .LCPI0_2] ; xmm0 = min(xmm0, 255.0)  | as u8
        cvttss2si       eax, xmm0                ; convert xmm0 to int      |
        ret
```

Note that this is only a single instruction more than optimized `unsafe` floating-point conversion.

It's somewhat disappointing that the main obstacle towards performant safe numeric conversions is the compiler's inability to reason about floating-point numbers. While floating-point optimizations are, of course, a can of worms best left unopened, this seems simple enough for the compiler to handle.

## Safer `unsafe`

As discussed above, the only difference between the hand-optimized assembly of the safe version and the generated assembly of the `unsafe` version is the `min` operation. So what if we just add a `min` operation to the `unsafe` version?

```rust
fn u5_to_u8_safer(x: u8) -> u8 {
    debug_assert!(x < 32);
    let f = x as f32 * (255.0 / 31.0) + 0.5;
    let g = f.min(255.0);
    unsafe { g.to_int_unchecked() }
}
```

The main advantage of this version is that it's safer. Since `g` is always in the range 0.5 to 255, `to_int_unchecked` can never cause UB. This means that the caller doesn't need to worry about the function causing UB, which is a big plus.

The generated assembly should look familiar:

```asm
.LCPI0_0:
        .long   0x41039ce7 ; 8.22580624 (f32)
.LCPI0_1:
        .long   0x3f000000 ; 0.5 (f32)
.LCPI0_2:
        .long   0x437f0000 ; 255.0 (f32)
u5_to_u8_safer:
        movzx   eax, dil
        cvtsi2ss        xmm0, eax                ; xmm0 = x to f32
        mulss   xmm0, dword ptr [rip + .LCPI0_0] ; xmm0 = xmm0 * 8.22580624 (= 255/31)
        addss   xmm0, dword ptr [rip + .LCPI0_1] ; xmm0 = xmm0 + 0.5
        minss   xmm0, dword ptr [rip + .LCPI0_2] ; xmm0 = min(xmm0, 255.0)  | as u8
        cvttss2si       eax, xmm0                ; convert xmm0 to int      |
        ret
```

Let's see how it performs:

```
                    low       expected       high
u5_to_u8_naive     [11.108 µs 11.147 µs 11.195 µs]
u5_to_u8_v2        [1.3806 µs 1.3848 µs 1.3898 µs]
u5_to_u8_unsafe    [614.04 ns 615.98 ns 618.32 ns]
u5_to_u8_safer     [???]
```

Expectedly, it falls between `u5_to_u8_v2` and `u5_to_u8_unsafe` versions. The performance is the same as the `unsafe` version, but it's safer.
